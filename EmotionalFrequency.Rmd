```{r}
library(jsonlite);library(RedditExtractoR);library(tidyverse);library(purrr);library(tidytext); library(wordcloud2); library(textdata); library(syuzhet); library(lubridate); library(ggrepel); library(directlabels); library(ggthemes); library(sentimentr); library(gridExtra); library(plotly)
```

```{r}
#Naive Emotional Classification
filteredemotion1 <- filtered %>% sentimentr::get_sentences() %>% sentimentr::emotion()
```

group_by(Year) %>% top_n(3, rowSum) %>% ungroup() %>%
```{r}
#Time Graph of Emotions
emotion2 <- filteredemotion1 %>% dplyr::filter(emotion_count > 0) %>% arrange(date) %>% #only keep instances where an emotion count was recorded for a comment
  group_by(url, emotion_type) %>% #group by url link (i.e each news article) and emotions 
  summarise(Emotion_Percentage = sum(emotion_count)) %>% 
  pivot_wider(names_from = emotion_type, values_from = Emotion_Percentage) %>% #gets data in desired format of where rows correspond to each post and columns are counts of each emotion. 
  mutate(across(everything(), ~ replace_na(., 0))) %>% data.frame() %>% #removes all NA values
  select(-anger_negated, -fear_negated, -anticipation_negated, -joy_negated, -trust_negated, -sadness_negated, -surprise_negated,-disgust_negated, -trust) %>% #removes selected emotions
  mutate(rowSum = rowSums(select(.,-url)),
         Date = as.Date(Atop_Brexit_urls$date_utc), 
         Year = year(Date)) %>% #obtains sum of each row excluding the url column. attaches date of the Brexit url and converts it to date format. the dates should correspond to the correct urls as both Atop_Brexit_url and filteredemotion1 have been arranged from earliest to latest date. 
  arrange(Date) %>% 
  mutate(across(-c("Date","rowSum","url","Year"), ~ (./rowSum*100))) %>% #convert into percentages 
  group_by(Year) %>% 
  summarise(across(everything(), mean, na.rm = TRUE)) %>% #get average percentages for each year. 
  pivot_longer(-c("Date","url", "Year", "rowSum"), names_to = "Emotion", values_to = "Percentage") 
head(emotion2)
summary(emotion2)
```
plot1 <- ggplot(emotion2, aes(x = Date, y = Percentage, group = Emotion,text = paste('Emotion:',Emotion,'<br>Percentage',Percentage, '<br>Date:', as.Date(Date))))
title = "Reddit Emotional Prevalence between 2016-2023", 
subtitle = "Which emotions dominated Brexit-related reddit discussions over time?"
   guides(color = guide_legend(nrow = 1))

```{r}
#GGplot
plot1 <- ggplot(emotion2, aes(x = Year, y = Percentage, group = Emotion)) + 
  geom_line(aes(color = Emotion)) +
  labs(x = NULL) + 
    theme_fivethirtyeight()
```

```{r}
#Plotifying for interactive labels
plot2 <- ggplotly(plot1, tooltip = c("x", "y","group"), style = ggplot2) %>%
  layout(title = list(text = paste0("Reddit Emotional Prevalence between 2016-2023", "<br>", "<sup>", "Which emotions dominated Brexit-related reddit discussions over time?", "</sup>")), 
         legend = list(orientation = "h", xanchor = "center", x = 0.5), 
         yaxis = list(title = "Emotion Frequency Percentage (%)")) %>% 
  config(displayModeBar = FALSE)
plot2
```

```{r}
score1 <- filteredemotion1 %>% dplyr::filter(emotion_count > 0) %>% arrange(date) %>% #only keep instances where an emotion count was recorded for a comment
  group_by(url, emotion_type) %>% #group by url link (i.e each news article/post) and emotions 
  summarise(Mean_Score = mean(score)) %>% 
  pivot_wider(names_from = emotion_type, values_from = Mean_Score) %>% #gets data in desired format of where rows correspond to each post and columns are counts of each emotion. 
  mutate(across(everything(), ~ replace_na(., 0))) %>% data.frame() %>% #removes all NA values
  select(-anger_negated, -fear_negated, -anticipation_negated, -joy_negated, -trust_negated, -sadness_negated, -surprise_negated, -disgust_negated, -trust) %>% 
  mutate(Date = as.Date(Atop_Brexit_urls$date_utc), Year = year(Date)) %>% #attaches date of the Brexit url and converts it to date format. the dates should correspond to the correct urls as both Atop_Brexit_url and filteredemotion1 have been arranged from earliest to latest date. 
  arrange(Date) %>% 
  group_by(Year) %>% 
  summarise(across(everything(), mean, na.rm = TRUE)) %>% #get average percentages for each year. 
  pivot_longer(-c("Date","url", "Year"), names_to = "Emotion", values_to = "Mean Score") 
head(score1)
summary(score1)
```
linewidth = ifelse(Emotion == "Postmean", 1.5, 1), linetype = ifelse(Emotion == "Postmean", "dashed", "solid"))
    scale_linetype_manual(values = c(Postmean = "dashed")) +

```{r}
scoreplot1 <- ggplot(score1, aes(x = Year, y = `Mean Score`, group = Emotion)) + 
  geom_line(aes(color = Emotion)) +
  labs(x = NULL) + 
    theme_fivethirtyeight()
```

```{r}
scoreplot2 <- ggplotly(scoreplot1, tooltip = c("x", "y","group"), style = ggplot2) %>%
  layout(title = list(text = paste0("Reddit Emotional Score Associations between 2016-2023", "<br>", "<sup>", "Which emotional comments were associated with the highest scores (upvotes-downvotes) and how did it change over time?", "</sup>")), 
         legend = list(orientation = "h", xanchor = "center", x = 0.5), 
         yaxis = list(title = "Mean Score Associated with each emotion")) %>% 
  config(displayModeBar = FALSE) # put legend in center of x-axis 
scoreplot2
```



