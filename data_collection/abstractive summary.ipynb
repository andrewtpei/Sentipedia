{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"df_news_content.csv\")\n",
    "df = df.dropna()\n",
    "   \n",
    "paragraphs = df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamyeung/anaconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Original Paragraph  \\\n",
      "0    Sign up to our free Brexit and beyond email fo...   \n",
      "1    Something went wrong, please try again later.\\...   \n",
      "2    Ukip has been ordered to fully reveal details ...   \n",
      "3    Farage got stuck on his bus in Kent because pe...   \n",
      "4    Sign up for the View from Westminster email fo...   \n",
      "..                                                 ...   \n",
      "141  Rachel Maddow reports on a controversy in the ...   \n",
      "142  Sign up to our free Brexit and beyond email fo...   \n",
      "143  Sign up to our free Brexit and beyond email fo...   \n",
      "144  Advertisement\\n\\nLawson, former chairman of th...   \n",
      "145  Vote Leave badge: Almost every aspect of Briti...   \n",
      "\n",
      "                                               Summary  \n",
      "0    Andrew Griceâ€™s article on how Boris Johnson mi...  \n",
      "1    under one in 10 young people in Scotland think...  \n",
      "2    the ruling casts a shadow over the 2016 EU ref...  \n",
      "3    three men with balaclavas spotted greeted the ...  \n",
      "4    theresa may says her trade deal with the EU is...  \n",
      "..                                                 ...  \n",
      "141  prime minister is blocking the release of a re...  \n",
      "142  Emmanuel Macron has branded the leaders of the...  \n",
      "143  obscure rule is to be used to deny MPs a cruci...  \n",
      "144  ex-vote leave pro-Brexit lawson is applying fo...  \n",
      "145  a 21-year-old fashion student from Durham set ...  \n",
      "\n",
      "[146 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "summaries = []\n",
    "original_paragraphs = []\n",
    "\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    input_text = \"summarize: \" + paragraph\n",
    "    inputs = tokenizer.encode_plus(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=300, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    summaries.append(summary)\n",
    "    original_paragraphs.append(paragraph)\n",
    "\n",
    "\n",
    "data = {'Original Paragraph': original_paragraphs, 'Summary': summaries}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
